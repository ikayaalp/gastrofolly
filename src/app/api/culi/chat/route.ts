import { NextRequest, NextResponse } from 'next/server'
import { getServerSession } from 'next-auth'
import { authOptions } from '@/lib/auth'
import { prisma } from '@/lib/prisma'
import OpenAI from 'openai'

const SYSTEM_PROMPT = `Sen Culinora platformunun AI asistanÄ±sÄ±n. AdÄ±n "Culi".
Sadece ve sadece gastronomi, yemek tarifleri, piÅŸirme teknikleri, mutfak ekipmanlarÄ±, gÄ±da bilimi ve aÅŸÃ§Ä±lÄ±k konularÄ±nda yanÄ±t verirsin.

Kurallar:
1. KESÄ°NLÄ°KLE gastronomi dÄ±ÅŸÄ±ndaki konulara (siyaset, teknoloji, matematik, genel kÃ¼ltÃ¼r, spor vb.) cevap verme.
2. Gastronomi dÄ±ÅŸÄ± bir soru gelirse Ã§ok kibar bir dille "Ben sadece mutfak ve yemek konularÄ±nda uzmanÄ±m. Size tarifler, piÅŸirme teknikleri veya gastronomi dÃ¼nyasÄ± hakkÄ±nda yardÄ±mcÄ± olabilirim." ÅŸeklinde yanÄ±t ver ve konuyu yemeÄŸe getir.
3. TÃ¼rkÃ§e konuÅŸ.
4. Samimi, iÅŸtah aÃ§Ä±cÄ± ve profesyonel bir ÅŸef gibi konuÅŸ. Emoji kullanabilirsin ðŸ‘¨â€ðŸ³ðŸ¥˜.

FORMATLAMA KURALLARI (Ã‡ok Ã–nemli):
- YanÄ±tlarÄ± okunabilir kÄ±lmak iÃ§in **Markdown** formatÄ±nÄ± etkin kullan.
- **Malzeme listeleri** ve **adÄ±m adÄ±m tarifler** iÃ§in MUTLAKA madde iÅŸaretleri (- veya *) veya numaralÄ± listeler (1., 2.) kullan.
- Ã–nemli baÅŸlÄ±klarÄ± **kalÄ±n** (**BaÅŸlÄ±k**) veya kÃ¼Ã§Ã¼k baÅŸlÄ±k (### BaÅŸlÄ±k) olarak yaz.
- Paragraflar arasÄ±nda **Ã§ift satÄ±r boÅŸluÄŸu** bÄ±rak.
- Uzun, blok halinde metinler yazmaktan kaÃ§Ä±n. KÄ±sa, net ve taranabilir paragraflar oluÅŸtur.

Sen bir ÅŸefsin, kod yazamazsÄ±n, matematik Ã§Ã¶zemezsin, sadece yemek yaparsÄ±n ve yemek konuÅŸursun.`

interface ChatMessage {
    role: 'user' | 'assistant'
    content: string
}

export async function POST(request: NextRequest) {
    try {
        const session = await getServerSession(authOptions)
        if (!session?.user?.id) {
            return NextResponse.json({ error: 'Unauthorized' }, { status: 401 })
        }

        const { message, conversationId } = await request.json()

        if (!message || !conversationId) {
            return NextResponse.json({ error: 'Message and conversationId required' }, { status: 400 })
        }

        // Verify conversation ownership
        const conversation = await prisma.aiConversation.findFirst({
            where: { id: conversationId, userId: session.user.id },
            include: {
                messages: {
                    orderBy: { createdAt: 'asc' },
                    select: { role: true, content: true },
                },
            },
        })

        if (!conversation) {
            return NextResponse.json({ error: 'Conversation not found' }, { status: 404 })
        }

        // Save user message
        await prisma.aiMessage.create({
            data: {
                role: 'user',
                content: message,
                conversationId,
            },
        })

        // Fetch courses context for recommendations
        const courses = await prisma.course.findMany({
            where: { isPublished: true },
            select: {
                title: true,
                description: true,
                instructor: { select: { name: true } },
                category: { select: { name: true } },
            },
            take: 20,
        })

        const coursesContext = courses.map(c =>
            `- Kurs: "${c.title}" (${c.category.name})\n  EÄŸitmen: ${c.instructor.name}\n  AÃ§Ä±klama: ${c.description}`
        ).join('\n\n')

        const dynamicSystemPrompt = `${SYSTEM_PROMPT}\n\n## Culinora PLATFORMUNDAKÄ° GÃœNCEL KURSLAR:\n${coursesContext}`

        // Build message history for AI
        const aiMessages: ChatMessage[] = conversation.messages.map(m => ({
            role: m.role as 'user' | 'assistant',
            content: m.content,
        }))
        aiMessages.push({ role: 'user', content: message })

        const apiKey = process.env.GROQ_API_KEY
        if (!apiKey) {
            return NextResponse.json({ error: 'AI not configured' }, { status: 500 })
        }

        const openai = new OpenAI({
            apiKey,
            baseURL: 'https://api.groq.com/openai/v1',
        })

        const completion = await openai.chat.completions.create({
            model: 'llama-3.3-70b-versatile',
            messages: [
                { role: 'system', content: dynamicSystemPrompt },
                ...aiMessages,
            ],
            max_tokens: 1000,
            temperature: 0.7,
        })

        const reply = completion.choices[0]?.message?.content || 'ÃœzgÃ¼nÃ¼m, ÅŸu an yanÄ±t veremiyorum.'

        // Save assistant message
        await prisma.aiMessage.create({
            data: {
                role: 'assistant',
                content: reply,
                conversationId,
            },
        })

        // Auto-title: if this is the first message, generate a title from the user's message
        if (conversation.messages.length === 0) {
            const title = message.length > 40 ? message.substring(0, 40) + '...' : message
            await prisma.aiConversation.update({
                where: { id: conversationId },
                data: { title },
            })
        }

        // Update conversation timestamp
        await prisma.aiConversation.update({
            where: { id: conversationId },
            data: { updatedAt: new Date() },
        })

        return NextResponse.json({ reply })
    } catch (error: any) {
        console.error('Culi chat error:', error)

        if (error?.status === 429) {
            return NextResponse.json(
                { error: 'Ã‡ok fazla istek gÃ¶nderildi. LÃ¼tfen biraz bekleyin.' },
                { status: 429 }
            )
        }

        return NextResponse.json(
            { error: 'AI yanÄ±t veremedi. LÃ¼tfen tekrar deneyin.' },
            { status: 500 }
        )
    }
}
